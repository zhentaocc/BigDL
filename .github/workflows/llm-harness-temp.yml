name: LLM Harness Evalution

# Cancel previous runs in the PR when you push new commits
concurrency:
  group: ${{ github.workflow }}-llm-nightly-test-${{ github.event.pull_request.number || github.run_id }}
  cancel-in-progress: true

# Controls when the action will run.
on:
  # schedule:
  #   - cron: "00 13 * * *" # GMT time, 13:00 GMT == 21:00 China
  pull_request:
    branches: [main]
    paths:
      - ".github/workflows/llm-harness-temp.yml"
  # Allows you to run this workflow manually from the Actions tab
  workflow_dispatch:

# A workflow run is made up of one or more jobs that can run sequentially or in parallel
jobs:
  llm-harness-evalution:
    timeout-minutes: 1000
    outputs:
      output: ${{steps.echo_output.outputs.result}}
    strategy:
      fail-fast: false
      matrix:
        # include:
        #   python-version: "3.9"
        #   model_name: "stablelm-3b-4e1t"
        #   task: "arc"
        #   precision: "sym_int4" #options: sym_int4, fp4, nf4, mixed_4bit, fp8
        python-version: ["3.9"]
        model_name: [stablelm-3b-4e1t, llama13b]
        task: ["truthfulqa"]
        precision: [sym_int4] #options: sym_int4, fp4, nf4, mixed_4bit, fp8
        
    runs-on: ubuntu-latest
    env:
      ANALYTICS_ZOO_ROOT: ${{ github.workspace }}
      ORIGIN_DIR: /mnt/disk1/models
      HARNESS_HF_HOME: /mnt/disk1/harness_home
    steps:
      
      - name: echo
        id: echo_output
        shell: bash
        run: |
          echo 'result=${{ matrix.model_name }}' >> $GITHUB_OUTPUT
          
  get-output:
    needs: llm-harness-evalution
    timeout-minutes: 1000
    strategy:
      fail-fast: false
      matrix:
        # include:
        #   python-version: "3.9"
        #   model_name: "stablelm-3b-4e1t"
        #   task: "arc"
        #   precision: "sym_int4" #options: sym_int4, fp4, nf4, mixed_4bit, fp8
        python-version: ["3.9"]
        model_name: [stablelm-3b-4e1t, llama13b]
        task: ["truthfulqa"]
        precision: [sym_int4] #options: sym_int4, fp4, nf4, mixed_4bit, fp8
        
    runs-on: ubuntu-latest
    env:
      ANALYTICS_ZOO_ROOT: ${{ github.workspace }}
      ORIGIN_DIR: /mnt/disk1/models
      HARNESS_HF_HOME: /mnt/disk1/harness_home
    steps:
      
      - name: print
        shell: bash
        run: |
          echo ${{ needs.llm-harness-evalution.outputs.output}} 
          echo ${{ needs.llm-harness-evalution.outputs}} 